{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Vorlesung 'Syntax natürlicher Sprachen'***\n",
    "\n",
    "--- \n",
    "# Intro: Parsing als automatische Verarbeitung formaler Grammatiken\n",
    "- **formale Grammatik**: Modellierung der syntaktischen Struktur (eines Ausschnitts) natürlicher Sprache \n",
    "  - ermöglicht Generierung der wohlgeformten Sätze der Sprache\n",
    "  - durch wiederholte Regelanwendung und Rekursion: beliebig lange Sätze möglich \n",
    "- **Parsing-Algorithmus**: Verfahren zur Überprüfung einer Eingabe auf Wohlgeformtheit gemäß einer Grammatik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "## Syntaktische Regeln:\n",
    "    S -> NP VP\n",
    "    PP -> P NP\n",
    "    NP -> Det N\n",
    "    NP -> NP PP\n",
    "    NP -> Pron\n",
    "    VP -> V NP | VP PP\n",
    "##Lexikalische Regeln:\n",
    "    Pron -> 'I'      \n",
    "    Det -> 'an' | 'my'\n",
    "    N -> 'elephant' | 'pajamas'\n",
    "    V -> 'shot'\n",
    "    P -> 'in'\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generierung mit formaler Grammatik:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "an elephant shot an elephant\n",
      "an elephant shot an pajamas\n",
      "an elephant shot my elephant\n",
      "an elephant shot my pajamas\n",
      "an elephant shot I\n",
      "an pajamas shot an elephant\n",
      "an pajamas shot an pajamas\n",
      "an pajamas shot my elephant\n",
      "an pajamas shot my pajamas\n",
      "an pajamas shot I\n",
      "my elephant shot an elephant\n",
      "my elephant shot an pajamas\n",
      "my elephant shot my elephant\n",
      "my elephant shot my pajamas\n",
      "my elephant shot I\n",
      "my pajamas shot an elephant\n",
      "my pajamas shot an pajamas\n",
      "my pajamas shot my elephant\n",
      "my pajamas shot my pajamas\n",
      "my pajamas shot I\n",
      "I shot an elephant\n",
      "I shot an pajamas\n",
      "I shot my elephant\n",
      "I shot my pajamas\n",
      "I shot I\n"
     ]
    }
   ],
   "source": [
    "#Generierung (depth = maximale Anzahl an Regelanwendungen):\n",
    "from nltk.parse.generate import generate\n",
    "for sentence in generate(grammar, depth=5):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syntaktische Ambiguität"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'shot', 'an', 'elephant', 'in', 'my', 'pajamas']\n"
     ]
    }
   ],
   "source": [
    "sent = 'I shot an elephant in my pajamas'.split()\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP (Pron I))\n",
      "  (VP\n",
      "    (VP (V shot) (NP (Det an) (N elephant)))\n",
      "    (PP (P in) (NP (Det my) (N pajamas)))))\n",
      "      S                                       \n",
      " ┌────┴──────────────┐                         \n",
      " │                   VP                       \n",
      " │         ┌─────────┴──────────┐              \n",
      " │         VP                   PP            \n",
      " │    ┌────┴───┐            ┌───┴───┐          \n",
      " NP   │        NP           │       NP        \n",
      " │    │    ┌───┴─────┐      │   ┌───┴─────┐    \n",
      "Pron  V   Det        N      P  Det        N   \n",
      " │    │    │         │      │   │         │    \n",
      " I   shot  an     elephant  in  my     pajamas\n",
      "\n",
      "(S\n",
      "  (NP (Pron I))\n",
      "  (VP\n",
      "    (V shot)\n",
      "    (NP\n",
      "      (NP (Det an) (N elephant))\n",
      "      (PP (P in) (NP (Det my) (N pajamas))))))\n",
      "      S                                       \n",
      " ┌────┴──────────────┐                         \n",
      " │                   VP                       \n",
      " │    ┌──────────────┴──────┐                  \n",
      " │    │                     NP                \n",
      " │    │        ┌────────────┴───┐              \n",
      " │    │        │                PP            \n",
      " │    │        │            ┌───┴───┐          \n",
      " NP   │        NP           │       NP        \n",
      " │    │    ┌───┴─────┐      │   ┌───┴─────┐    \n",
      "Pron  V   Det        N      P  Det        N   \n",
      " │    │    │         │      │   │         │    \n",
      " I   shot  an     elephant  in  my     pajamas\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parser = nltk.ChartParser(grammar,trace=0)\n",
    "\n",
    "for tree in parser.parse(sent):\n",
    "    print(tree)\n",
    "    tree.pretty_print(unicodelines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Koordinationsambiguität"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(NP (NP (Adj alte) (NP (N Männer))) (Con und) (NP (N Frauen)))\n",
      "           NP             \n",
      "      ┌────┴─────┬────┐    \n",
      "      NP         │    │   \n",
      " ┌────┴────┐     │    │    \n",
      " │         NP    │    NP  \n",
      " │         │     │    │    \n",
      "Adj        N    Con   N   \n",
      " │         │     │    │    \n",
      "alte     Männer und Frauen\n",
      "\n",
      "(NP (Adj alte) (NP (NP (N Männer)) (Con und) (NP (N Frauen))))\n",
      "             NP           \n",
      " ┌───────────┴───┐         \n",
      " │               NP       \n",
      " │     ┌─────────┼────┐    \n",
      " │     NP        │    NP  \n",
      " │     │         │    │    \n",
      "Adj    N        Con   N   \n",
      " │     │         │    │    \n",
      "alte Männer     und Frauen\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "## linke Seite erster Regel = Startsymbol:\n",
    "    NP -> NP Con NP\n",
    "    NP -> Adj NP\n",
    "    NP -> N\n",
    "    Con -> 'und'\n",
    "    Adj -> 'alte'\n",
    "    N -> 'Männer' | 'Frauen'\n",
    "\"\"\")\n",
    "\n",
    "sent = 'alte Männer und Frauen'.split()\n",
    "\n",
    "parser = nltk.ChartParser(grammar,trace=0)\n",
    "\n",
    "for tree in parser.parse(sent):\n",
    "    print(tree)\n",
    "    tree.pretty_print(unicodelines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Koordination: nur gleiche Phrasen!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hund und Hund\n",
      "Hund und Katze\n",
      "Hund und Esel\n",
      "Hund und groß\n",
      "Hund und klein\n",
      "Katze und Hund\n",
      "Katze und Katze\n",
      "Katze und Esel\n",
      "Katze und groß\n",
      "Katze und klein\n",
      "Esel und Hund\n",
      "Esel und Katze\n",
      "Esel und Esel\n",
      "Esel und groß\n",
      "Esel und klein\n",
      "groß und Hund\n",
      "groß und Katze\n",
      "groß und Esel\n",
      "groß und groß\n",
      "groß und klein\n",
      "klein und Hund\n",
      "klein und Katze\n",
      "klein und Esel\n",
      "klein und groß\n",
      "klein und klein\n",
      "Hund\n",
      "Katze\n",
      "Esel\n",
      "groß\n",
      "klein\n"
     ]
    }
   ],
   "source": [
    "#Grammatik ohne Einschränkung der Koordination auf gleichartige Phrasen:\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    XP -> XP Con XP\n",
    "    XP -> NP | ADJP\n",
    "    NP -> N\n",
    "    ADJP -> Adj\n",
    "    Con -> 'und'\n",
    "    N -> 'Hund' | 'Katze' | 'Esel'\n",
    "    Adj -> 'groß' | 'klein'\n",
    "\"\"\")\n",
    "\n",
    "#Generierung:\n",
    "from nltk.parse.generate import generate\n",
    "for sentence in generate(grammar, depth=5):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Temporale Ambiguität (Backtracking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = 'the old man the boat'.split()\n",
    "\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "## Syntaktische Regeln:\n",
    "    S -> NP VP\n",
    "    NP -> Det Adj N\n",
    "    NP -> Det N\n",
    "    VP -> V NP\n",
    "##Lexikalische Regeln:\n",
    "    Det -> 'the'\n",
    "    Adj -> 'old'    \n",
    "    N -> 'man' | 'boat' | 'old'\n",
    "    V -> 'man'\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Adj -> 'old' will never be used\n",
      "Warning: N -> 'man' will never be used\n",
      "Parsing 'the old man the boat'\n",
      "    [ * the old man the boat]\n",
      "  S [ 'the' * old man the boat]\n",
      "  R [ Det * old man the boat]\n",
      "  S [ Det 'old' * man the boat]\n",
      "  R [ Det Adj * man the boat]\n",
      "  S [ Det Adj 'man' * the boat]\n",
      "  R [ Det Adj N * the boat]\n",
      "  R [ NP * the boat]\n",
      "  S [ NP 'the' * boat]\n",
      "  R [ NP Det * boat]\n",
      "  S [ NP Det 'boat' * ]\n",
      "  R [ NP Det N * ]\n",
      "  R [ NP NP * ]\n"
     ]
    }
   ],
   "source": [
    "#NLTK-ShiftReduceParser: kein Backtracking! \n",
    "#bleibt bei Analyse NP NP ((the old man) (the boat)) stehen, findet keinen vollständigen Parse\n",
    "\n",
    "parser = nltk.ShiftReduceParser(grammar,trace=2)\n",
    "\n",
    "for tree in parser.parse(sent):\n",
    "    print(tree)\n",
    "    tree.pretty_print(unicodelines=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing 'the old man the boat'\n",
      "Start:\n",
      "    [ * S ]\n",
      "Expand: S -> NP VP\n",
      "    [ * NP VP ]\n",
      "Expand: NP -> Det Adj N\n",
      "    [ * Det Adj N VP ]\n",
      "Expand: Det -> 'the'\n",
      "    [ * 'the' Adj N VP ]\n",
      "Match: 'the'\n",
      "    [ 'the' * Adj N VP ]\n",
      "Expand: Adj -> 'old'\n",
      "    [ 'the' * 'old' N VP ]\n",
      "Match: 'old'\n",
      "    [ 'the' 'old' * N VP ]\n",
      "Expand: N -> 'man'\n",
      "    [ 'the' 'old' * 'man' VP ]\n",
      "Match: 'man'\n",
      "    [ 'the' 'old' 'man' * VP ]\n",
      "Expand: VP -> V NP\n",
      "    [ 'the' 'old' 'man' * V NP ]\n",
      "Expand: V -> 'man'\n",
      "    [ 'the' 'old' 'man' * 'man' NP ]\n",
      "Backtrack: 'the' match failed\n",
      "Expand: N -> 'boat'\n",
      "    [ 'the' 'old' * 'boat' VP ]\n",
      "Backtrack: 'man' match failed\n",
      "Expand: N -> 'old'\n",
      "    [ 'the' 'old' * 'old' VP ]\n",
      "Backtrack: 'man' match failed\n",
      "Expand: NP -> Det N\n",
      "    [ * Det N VP ]\n",
      "Expand: Det -> 'the'\n",
      "    [ * 'the' N VP ]\n",
      "Match: 'the'\n",
      "    [ 'the' * N VP ]\n",
      "Expand: N -> 'man'\n",
      "    [ 'the' * 'man' VP ]\n",
      "Backtrack: 'old' match failed\n",
      "Expand: N -> 'boat'\n",
      "    [ 'the' * 'boat' VP ]\n",
      "Backtrack: 'old' match failed\n",
      "Expand: N -> 'old'\n",
      "    [ 'the' * 'old' VP ]\n",
      "Match: 'old'\n",
      "    [ 'the' 'old' * VP ]\n",
      "Expand: VP -> V NP\n",
      "    [ 'the' 'old' * V NP ]\n",
      "Expand: V -> 'man'\n",
      "    [ 'the' 'old' * 'man' NP ]\n",
      "Match: 'man'\n",
      "    [ 'the' 'old' 'man' * NP ]\n",
      "Expand: NP -> Det Adj N\n",
      "    [ 'the' 'old' 'man' * Det Adj N ]\n",
      "Expand: Det -> 'the'\n",
      "    [ 'the' 'old' 'man' * 'the' Adj N ]\n",
      "Match: 'the'\n",
      "    [ 'the' 'old' 'man' 'the' * Adj N ]\n",
      "Expand: Adj -> 'old'\n",
      "    [ 'the' 'old' 'man' 'the' * 'old' N ]\n",
      "Backtrack: 'boat' match failed\n",
      "Expand: NP -> Det N\n",
      "    [ 'the' 'old' 'man' * Det N ]\n",
      "Expand: Det -> 'the'\n",
      "    [ 'the' 'old' 'man' * 'the' N ]\n",
      "Match: 'the'\n",
      "    [ 'the' 'old' 'man' 'the' * N ]\n",
      "Expand: N -> 'man'\n",
      "    [ 'the' 'old' 'man' 'the' * 'man' ]\n",
      "Backtrack: 'boat' match failed\n",
      "Expand: N -> 'boat'\n",
      "    [ 'the' 'old' 'man' 'the' * 'boat' ]\n",
      "Match: 'boat'\n",
      "    [ 'the' 'old' 'man' 'the' 'boat' ]\n",
      "GOOD PARSE:\n",
      "    [ 'the' 'old' 'man' 'the' 'boat' ]\n",
      "(S (NP (Det the) (N old)) (VP (V man) (NP (Det the) (N boat))))\n",
      "             S              \n",
      "     ┌───────┴───┐           \n",
      "     │           VP         \n",
      "     │       ┌───┴───┐       \n",
      "     NP      │       NP     \n",
      " ┌───┴───┐   │   ┌───┴───┐   \n",
      "Det      N   V  Det      N  \n",
      " │       │   │   │       │   \n",
      "the     old man the     boat\n",
      "\n",
      "Expand: N -> 'old'\n",
      "    [ 'the' 'old' 'man' 'the' * 'old' ]\n",
      "Backtrack: 'boat' match failed\n"
     ]
    }
   ],
   "source": [
    "##Reanalyse der Struktur durch Backtracking mit RecursiveDescentParser:\n",
    "\n",
    "parser = nltk.RecursiveDescentParser(grammar,trace=3)\n",
    "\n",
    "for tree in parser.parse(sent):\n",
    "    print(tree)\n",
    "    tree.pretty_print(unicodelines=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Verarbeitung von CFGs mit verschiedenen Parsern\n",
    "\n",
    "- Recursive-Descent-Parser kann keine linksrekursiven Regeln verarbeiten!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'shot', 'an', 'elephant']\n"
     ]
    }
   ],
   "source": [
    "sent = 'I shot an elephant'.split()\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "## Syntaktische Regeln:\n",
    "    S -> NP VP\n",
    "    PP -> P NP\n",
    "    NP -> Det N \n",
    "#rekursive Regel:\n",
    "    NP -> NP PP\n",
    "    NP -> Pron\n",
    "    VP -> V NP\n",
    "#rekursive Regel:    \n",
    "    VP -> VP PP\n",
    "##Lexikalische Regeln:\n",
    "    Pron -> 'I'      \n",
    "    Det -> 'an' | 'my'\n",
    "    N -> 'elephant' | 'pajamas'\n",
    "    V -> 'shot'\n",
    "    P -> 'in'\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Shift-Reduce-Parser (bottom-up)\n",
    "- https://www.nltk.org/book/ch08.html#shift-reduce-parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing 'I shot an elephant'\n",
      "    [ * I shot an elephant]\n",
      "  S [ 'I' * shot an elephant]\n",
      "  R [ Pron * shot an elephant]\n",
      "  R [ NP * shot an elephant]\n",
      "  S [ NP 'shot' * an elephant]\n",
      "  R [ NP V * an elephant]\n",
      "  S [ NP V 'an' * elephant]\n",
      "  R [ NP V Det * elephant]\n",
      "  S [ NP V Det 'elephant' * ]\n",
      "  R [ NP V Det N * ]\n",
      "  R [ NP V NP * ]\n",
      "  R [ NP VP * ]\n",
      "  R [ S * ]\n",
      "(S (NP (Pron I)) (VP (V shot) (NP (Det an) (N elephant))))\n",
      "           S                  \n",
      "  _________|___                \n",
      " |             VP             \n",
      " |     ________|___            \n",
      " NP   |            NP         \n",
      " |    |         ___|_____      \n",
      "Pron  V       Det        N    \n",
      " |    |        |         |     \n",
      " I   shot      an     elephant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parser = nltk.ShiftReduceParser(grammar,trace=2)\n",
    "for tree in parser.parse(sent):\n",
    "    print(tree)\n",
    "    tree.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chart-Parser (bottom-up)\n",
    "- https://www.nltk.org/book/ch08.html#well-formed-substring-tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|.    I    .   shot  .    an   . elephant.|\n",
      "|[---------]         .         .         .| [0:1] 'I'\n",
      "|.         [---------]         .         .| [1:2] 'shot'\n",
      "|.         .         [---------]         .| [2:3] 'an'\n",
      "|.         .         .         [---------]| [3:4] 'elephant'\n",
      "|[---------]         .         .         .| [0:1] Pron -> 'I' *\n",
      "|[---------]         .         .         .| [0:1] NP -> Pron *\n",
      "|[--------->         .         .         .| [0:1] S  -> NP * VP\n",
      "|[--------->         .         .         .| [0:1] NP -> NP * PP\n",
      "|.         [---------]         .         .| [1:2] V  -> 'shot' *\n",
      "|.         [--------->         .         .| [1:2] VP -> V * NP\n",
      "|.         .         [---------]         .| [2:3] Det -> 'an' *\n",
      "|.         .         [--------->         .| [2:3] NP -> Det * N\n",
      "|.         .         .         [---------]| [3:4] N  -> 'elephant' *\n",
      "|.         .         [-------------------]| [2:4] NP -> Det N *\n",
      "|.         .         [------------------->| [2:4] S  -> NP * VP\n",
      "|.         .         [------------------->| [2:4] NP -> NP * PP\n",
      "|.         [-----------------------------]| [1:4] VP -> V NP *\n",
      "|.         [----------------------------->| [1:4] VP -> VP * PP\n",
      "|[=======================================]| [0:4] S  -> NP VP *\n",
      "(S (NP (Pron I)) (VP (V shot) (NP (Det an) (N elephant))))\n",
      "           S                  \n",
      "  _________|___                \n",
      " |             VP             \n",
      " |     ________|___            \n",
      " NP   |            NP         \n",
      " |    |         ___|_____      \n",
      "Pron  V       Det        N    \n",
      " |    |        |         |     \n",
      " I   shot      an     elephant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parser = nltk.ChartParser(grammar,trace=1)\n",
    "for tree in parser.parse(sent):\n",
    "    print(tree)\n",
    "    tree.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive-Descent-Parser (top-down)\n",
    "- https://www.nltk.org/book/ch08.html#recursive-descent-parsing\n",
    "\n",
    "- Endlosschleife bei linksrekursiver Regel!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parser = nltk.RecursiveDescentParser(grammar,trace=2)\n",
    "#for tree in parser.parse(sent):\n",
    "#    print(tree)\n",
    "#    tree.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Parsing 'I shot an elephant'\n",
    "    [ * S ]\n",
    "  E [ * NP VP ]\n",
    "  E [ * Det N VP ]\n",
    "  E [ * 'an' N VP ]\n",
    "  E [ * 'my' N VP ]\n",
    "  E [ * NP PP VP ]\n",
    "  E [ * Det N PP VP ]\n",
    "  E [ * 'an' N PP VP ]\n",
    "  E [ * 'my' N PP VP ]\n",
    "  E [ * NP PP PP VP ]\n",
    "  E [ * Det N PP PP VP ]\n",
    "  E [ * 'an' N PP PP VP ]\n",
    "  E [ * 'my' N PP PP VP ]\n",
    "  E [ * NP PP PP PP VP ]\n",
    "  E [ * Det N PP PP PP VP ]\n",
    "  E [ * 'an' N PP PP PP VP ]\n",
    "  E [ * 'my' N PP PP PP VP ]\n",
    "  E [ * NP PP PP PP PP VP ]\n",
    "  E [ * Det N PP PP PP PP VP ]\n",
    "  E [ * 'an' N PP PP PP PP VP ]\n",
    "  E [ * 'my' N PP PP PP PP VP ]\n",
    "  E [ * NP PP PP PP PP PP VP ]\n",
    "  E [ * Det N PP PP PP PP PP VP ]\n",
    "  E [ * 'an' N PP PP PP PP PP VP ]\n",
    "  E [ * 'my' N PP PP PP PP PP VP ]\n",
    "  E [ * NP PP PP PP PP PP PP VP ]\n",
    "  E [ * Det N PP PP PP PP PP PP VP ]\n",
    "  E [ * 'an' N PP PP PP PP PP PP VP ]\n",
    "  E [ * 'my' N PP PP PP PP PP PP VP ]\n",
    "  E [ * NP PP PP PP PP PP PP PP VP ]\n",
    "  E [ * Det N PP PP PP PP PP PP PP VP ]\n",
    "  E [ * 'an' N PP PP PP PP PP PP PP VP ]\n",
    "  E [ * 'my' N PP PP PP PP PP PP PP VP ]\n",
    "  E [ * NP PP PP PP PP PP PP PP PP VP ]\n",
    "  E [ * Det N PP PP PP PP PP PP PP PP VP ]\n",
    "  E [ * 'an' N PP PP PP PP PP PP PP PP VP ]\n",
    "  E [ * 'my' N PP PP PP PP PP PP PP PP VP ]\n",
    "  E [ * NP PP PP PP PP PP PP PP PP PP VP ]\n",
    "  E [ * Det N PP PP PP PP PP PP PP PP PP VP ]\n",
    "  E [ * 'an' N PP PP PP PP PP PP PP PP PP VP ]\n",
    "  E [ * 'my' N PP PP PP PP PP PP PP PP PP VP ]\n",
    "  E [ * NP PP PP PP PP PP PP PP PP PP PP VP ]\n",
    "  E [ * Det N PP PP PP PP PP PP PP PP PP PP VP ]\n",
    "  E [ * 'an' N PP PP PP PP PP PP PP PP PP PP VP ]\n",
    "  E [ * 'my' N PP PP PP PP PP PP PP PP PP PP VP ]\n",
    "  E [ * NP PP PP PP PP PP PP PP PP PP PP PP VP ]\n",
    "  E [ * Det N PP PP PP PP PP PP PP PP PP PP PP VP ]\n",
    "  E [ * 'an' N PP PP PP PP PP PP PP PP PP PP PP VP ]\n",
    "  E [ * 'my' N PP PP PP PP PP PP PP PP PP PP PP VP ]\n",
    "  E [ * NP PP PP PP PP PP PP PP PP PP PP PP PP VP ]\n",
    "  E [ * Det N PP PP PP PP PP PP PP PP PP PP PP PP VP ]\n",
    "  E [ * 'an' N PP PP PP PP PP PP PP PP PP PP PP PP VP ]\n",
    "  E [ * 'my' N PP PP PP PP PP PP PP PP PP PP PP PP VP ]\n",
    "  E [ * NP PP PP PP PP PP PP PP PP PP PP PP PP PP VP ]\n",
    "  E [ * Det N PP PP PP PP PP PP PP PP PP PP PP PP PP VP ]\n",
    "  E [ * 'an' N PP PP PP PP PP PP PP PP PP PP PP PP PP VP ]\n",
    "  E [ * 'my' N PP PP PP PP PP PP PP PP PP PP PP PP PP VP ]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "---\n",
    "\n",
    "# Dependenzgrammatik: Verarbeitung nicht-projektiver Strukturen\n",
    "\n",
    "- (Dependenzgrammatik im NLTK: https://www.nltk.org/book/ch08.html#dependencies-and-dependency-grammar)\n",
    "\n",
    "- nicht-projektive (diskontinuierliche) Strukturen können mit Dependenzgrammatiken modelliert werden, da sie (im Gegensatz zu Konstituentengrammatiken) von der linearen Anordnung abstrahieren (Modellierung der Abhängigkeitsbeziehungen)\n",
    "- allerdings können in der Verarbeitung von Dependenzgrammatiken (Dependency Parsing) solche Strukturen Probleme bereiten\n",
    "- vgl. https://en.wikipedia.org/wiki/Discontinuity_(linguistics)#Projectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = nltk.DependencyGrammar.fromstring(\"\"\"\n",
    "    'Hund' -> 'ein' | ','\n",
    "    'verstummte' -> 'Hund'\n",
    "    'Hund' -> 'gebellt'\n",
    "    'gebellt' -> 'der' | 'vorher' | 'hatte'\n",
    "    'laut' -> 'sehr'\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### projektive Struktur: *Relativsatz*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ein', 'Hund', ',', 'der', 'vorher', 'gebellt', 'hatte', ',', 'verstummte']\n"
     ]
    }
   ],
   "source": [
    "sent = 'ein Hund , der vorher gebellt hatte , verstummte'.split()\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(verstummte (Hund ein , (gebellt der vorher hatte) ,))\n",
      "        verstummte                  \n",
      "            │                        \n",
      "           Hund                     \n",
      " ┌───┬──────┼─────────────┐          \n",
      " │   │      │          gebellt      \n",
      " │   │      │       ┌─────┼──────┐   \n",
      "ein  ,      ,      der  vorher hatte\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parser = nltk.ProjectiveDependencyParser(grammar)\n",
    "\n",
    "for tree in parser.parse(sent):\n",
    "    print(tree)\n",
    "    tree.pretty_print(unicodelines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nicht-projektive Struktur (*long distance dependency*): *ins Nachfeld extrahierter Relativsatz*\n",
    "- *verstummte* wird in die komplexe Nominalphrase eingeschoben\n",
    "- Überschneidung von Kanten: der Dependent (*gebellt*) von *Hund* folgt nach dessen Kopf (*verstummte*) \n",
    "- (Details dazu in Sitzung 11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ein', 'Hund', 'verstummte', ',', 'der', 'vorher', 'gebellt', 'hatte']\n"
     ]
    }
   ],
   "source": [
    "sent = 'ein Hund verstummte , der vorher gebellt hatte'.split()\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kein Parse mit ProjectiveDependencyParser!\n",
    "parser = nltk.ProjectiveDependencyParser(grammar)\n",
    "\n",
    "for tree in parser.parse(sent):\n",
    "    print(tree)\n",
    "    tree.pretty_print(unicodelines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verstummte\n",
      "1 ein: []\n",
      "2 Hund: [1, 4, 7]\n",
      "3 verstummte: [2]\n",
      "4 ,: []\n",
      "5 der: []\n",
      "6 vorher: []\n",
      "7 gebellt: [5, 6, 8]\n",
      "8 hatte: []\n",
      "\n",
      " (verstummte (Hund ein , (gebellt der vorher hatte))) \n",
      "\n",
      "        verstummte              \n",
      "            │                    \n",
      "           Hund                 \n",
      " ┌───┬──────┴─────────┐          \n",
      " │   │             gebellt      \n",
      " │   │      ┌─────────┼──────┐   \n",
      "ein  ,     der      vorher hatte\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#NonprojectiveDependencyParser: erkennt Struktur korrekt\n",
    "#Code s. http://www.nltk.org/howto/dependency.html:\n",
    "\n",
    "dp = nltk.NonprojectiveDependencyParser(grammar)\n",
    "g, = dp.parse(sent)\n",
    "\n",
    "print(g.root['word'])\n",
    "\n",
    "for _, node in sorted(g.nodes.items()):\n",
    "    if node['word'] is not None:\n",
    "        print('{address} {word}: {d}'.format(d=node['deps'][''], **node))\n",
    "\n",
    "print('\\n', g.tree(), '\\n')\n",
    "g.tree().pretty_print(unicodelines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "098dd75f65594c0f992ddeffeb8523e3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.2.0",
      "model_name": "SliderStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "0ccfa5129ab64950adda077f6ac8f44a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.2.0",
      "model_name": "IntSliderModel",
      "state": {
       "layout": "IPY_MODEL_641f3cf31a334ee6810a9a92f93e89a7",
       "style": "IPY_MODEL_63aadafcc3504a3b8b15fdea9d4ec244",
       "value": 50
      }
     },
     "1b37a149a74c40c68d34c61b481048f8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "367694b2ecc94715a20952236f9ced88": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3d6ebd239fc84a8e95b3007988e38134": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.2.0",
      "model_name": "SliderStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "63aadafcc3504a3b8b15fdea9d4ec244": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.2.0",
      "model_name": "SliderStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "641f3cf31a334ee6810a9a92f93e89a7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "993ec756027845c19085347ca5f9f6ce": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.2.0",
      "model_name": "SliderStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "bb743dc2dd2d4bb08dd2c5255e1d87c6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.2.0",
      "model_name": "SliderStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "cb4a4abdac584f78ac3b37579ac33b10": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.2.0",
      "model_name": "IntSliderModel",
      "state": {
       "layout": "IPY_MODEL_f25c2eb22704411b9981f8047a2c0182",
       "style": "IPY_MODEL_993ec756027845c19085347ca5f9f6ce",
       "value": 50
      }
     },
     "cfbb8ba5969a49e18a1733c50e6b73e4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.2.0",
      "model_name": "IntSliderModel",
      "state": {
       "layout": "IPY_MODEL_1b37a149a74c40c68d34c61b481048f8",
       "style": "IPY_MODEL_3d6ebd239fc84a8e95b3007988e38134",
       "value": 50
      }
     },
     "da2e37629b7141b8a194c275f89ccef5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "eafa48b852af4f40b414b8d4f0b90c7a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.2.0",
      "model_name": "IntSliderModel",
      "state": {
       "layout": "IPY_MODEL_da2e37629b7141b8a194c275f89ccef5",
       "style": "IPY_MODEL_bb743dc2dd2d4bb08dd2c5255e1d87c6"
      }
     },
     "f196171317cf493fabedf854f59c1d44": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.2.0",
      "model_name": "IntSliderModel",
      "state": {
       "layout": "IPY_MODEL_367694b2ecc94715a20952236f9ced88",
       "style": "IPY_MODEL_098dd75f65594c0f992ddeffeb8523e3"
      }
     },
     "f25c2eb22704411b9981f8047a2c0182": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
