{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Vorlesung 'Syntax natürlicher Sprachen'***\n",
    "\n",
    "---\n",
    "# PCFG: Abschätzung von Regelwahrscheinlichkeiten aus CFG-Korpusdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from nltk.corpus import treebank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_relevant_constructions(lhs, only_with=None):\n",
    "    lhs_nt = nltk.grammar.Nonterminal(lhs)\n",
    "    should_filter = only_with is not None\n",
    "    if should_filter:\n",
    "        filter_by = list(map(nltk.grammar.Nonterminal, only_with))\n",
    "        def passes_filter(tup):\n",
    "            for f in filter_by:\n",
    "                if f not in tup:\n",
    "                    return False\n",
    "            return True\n",
    "\n",
    "    counter = defaultdict(int)\n",
    "    ### zähle Produktionen in treebank mit lhs als linker Seite ###\n",
    "    ### und einer rechten Seite, für die passes_filter True liefert ###\n",
    "    for tree in treebank.parsed_sents():  # [(S (NP DET N) (VP V NP))]\n",
    "        for prod in tree.productions():   # [(S, NP VP), (NP, DET N)]\n",
    "            if prod.lhs() == lhs_nt:\n",
    "                if not should_filter or passes_filter(prod.rhs()):\n",
    "                    counter[prod] += 1\n",
    "\n",
    "    return [ (k, counter[k]) for k in sorted(counter.keys(), key=counter.__getitem__) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1: Herunterladen von Ressourcen\n",
    "\n",
    "#### Laden Sie sich zunächst die Ressource `corpora/treebank` über den NLTK Download-Manager herunter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2: Von Daten zu Regelwahrscheinlichkeiten\n",
    "\n",
    "#### Gegeben sei folgende kontextfreie Grammatik:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "VP -> V NP PP\n",
    "VP -> V NP\n",
    "NP -> DET N\n",
    "NP -> NP PP\n",
    "PP -> P NP\n",
    "\n",
    "DET -> \"the\" | \"a\"\n",
    "N -> \"boy\" | \"woman\" | \"telescope\"\n",
    "V -> \"saw\"\n",
    "P -> \"with\"\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sie modelliert sehr einfache Sätze der Form `SBJ` *saw* `OBJ` mit optionaler Präpositionalphrase am Ende. Diese Präpositionalphrase kann entweder der näheren Bestimmung des Objekts oder der näheren Bestimmung der in der Verbalphrase ausgedrückten Handlung dienen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 S                                  \n",
      "     ┌───────────┴────────┐                          \n",
      "     │                    VP                        \n",
      "     │       ┌───────┬────┴─────────┐                \n",
      "     │       │       │              PP              \n",
      "     │       │       │         ┌────┴───┐            \n",
      "     NP      │       NP        │        NP          \n",
      " ┌───┴───┐   │   ┌───┴────┐    │    ┌───┴──────┐     \n",
      "DET      N   V  DET       N    P   DET         N    \n",
      " │       │   │   │        │    │    │          │     \n",
      "the     boy saw  a      woman with  a      telescope\n",
      "\n",
      "                 S                                  \n",
      "     ┌───────────┴────────┐                          \n",
      "     │                    VP                        \n",
      "     │       ┌────────────┴────┐                     \n",
      "     │       │                 NP                   \n",
      "     │       │       ┌─────────┴────┐                \n",
      "     │       │       │              PP              \n",
      "     │       │       │         ┌────┴───┐            \n",
      "     NP      │       NP        │        NP          \n",
      " ┌───┴───┐   │   ┌───┴────┐    │    ┌───┴──────┐     \n",
      "DET      N   V  DET       N    P   DET         N    \n",
      " │       │   │   │        │    │    │          │     \n",
      "the     boy saw  a      woman with  a      telescope\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = \"the boy saw a woman with a telescope\"\n",
    "parser = nltk.ChartParser(grammar,trace=0)\n",
    "\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree.pretty_print(unicodelines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    " \n",
    "#### Im folgenden sollen aus der Penn Treebank Wahrscheinlichkeiten für die einzelnen Regeln extrahiert werden, um dieser Ambiguität Herr zu werden.\n",
    "\n",
    "#### Nutzen Sie das im NLTK enthaltene Sample der Penn Treebank (nach Installation unter `nltk.corpus.treebank` zu finden) zunächst zur Identifikation der für eine Disambiguierung nützlichen (Teil-)bäume der Penn Treebank.\n",
    "\n",
    "#### *Hinweis:* Sie können sich bei der Analyse auf die häufigsten Konstruktionen der Baumbank beschränken."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2.1: Regelwahrscheinlichkeiten für VP-Regeln abschätzen\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Zählen Sie zunächst für die V+NP+PP-Konstruktion, wie oft sie in der Penn Treebank vorkommen und berechnen Sie die relativen Häufigkeiten als Approximation der Regelwahrscheinlichkeiten:\n",
    "\n",
    "$$P(V, N\\!P, P\\!P \\mid V\\!P) = \\dfrac{count(V\\!P \\rightarrow V\\:N\\!P\\:P\\!P)}{count(V\\!P \\rightarrow \\setminus*)}$$\n",
    "\n",
    "**hier (vgl. Grammatik):**\n",
    "\n",
    "$$= \\dfrac{count(V\\!P \\rightarrow V\\:N\\!P\\:P\\!P)}{count(V\\!P \\rightarrow V\\:N\\!P\\:P\\!P) + count(V\\!P \\rightarrow V\\:N\\!P)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(VP -> VBZ NP-PRD, 163),\n",
       " (VP -> VBN NP PP, 170),\n",
       " (VP -> VBN NP PP-CLR, 178),\n",
       " (VP -> VBP NP, 185),\n",
       " (VP -> VBZ SBAR, 197),\n",
       " (VP -> VBZ S, 215),\n",
       " (VP -> VBD S, 223),\n",
       " (VP -> VP CC VP, 234),\n",
       " (VP -> VBN NP, 250),\n",
       " (VP -> VB VP, 258),\n",
       " (VP -> VBZ NP, 261),\n",
       " (VP -> VBP VP, 337),\n",
       " (VP -> VBD VP, 361),\n",
       " (VP -> VBG NP, 375),\n",
       " (VP -> VBD NP, 378),\n",
       " (VP -> VBZ VP, 459),\n",
       " (VP -> VBD SBAR, 631),\n",
       " (VP -> MD VP, 759),\n",
       " (VP -> VB NP, 805),\n",
       " (VP -> TO VP, 1257)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constructions = find_relevant_constructions('VP')\n",
    "constructions[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.12585895117540688, 0.8741410488245931)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vp_v_np_pp_frq = 178 + 170\n",
    "vp_v_np_without_frq = 805 + 378 + 375 + 261 + 250 + 185 + 163\n",
    "\n",
    "vp_with_pp = vp_v_np_pp_frq / (vp_v_np_pp_frq + vp_v_np_without_frq)\n",
    "vp_without = vp_v_np_without_frq / (vp_v_np_pp_frq + vp_v_np_without_frq)\n",
    "\n",
    "(vp_with_pp, vp_without)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2.2: Regelwahrscheinlichkeiten für NP-Regeln abschätzen\n",
    "\n",
    "#### Zählen Sie anschließend, wie oft die NP+PP-Konstruktion in der Penn Treebank vorkommt und berechnen Sie die relativen Häufigkeiten als Approximation der Regelwahrscheinlichkeiten. Das Vorgehen wird in folgender Formel veranschaulicht:\n",
    "\n",
    "$$P(N\\!P, P\\!P \\mid N\\!P) = \\dfrac{count(N\\!P \\rightarrow \\:N\\!P\\:P\\!P)}{count(N\\!P \\rightarrow \\setminus*)}$$\n",
    "\n",
    "**hier:**\n",
    "\n",
    "$$= \\dfrac{count(N\\!P \\rightarrow \\:N\\!P\\:P\\!P)}{count(N\\!P \\rightarrow \\:N\\!P\\:P\\!P) + count(N\\!P \\rightarrow DET\\:N\\!P)}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(NP -> PRP, 280),\n",
       " (NP -> NNP NNP NNP, 282),\n",
       " (NP -> NP CC NP, 289),\n",
       " (NP -> NN NNS, 304),\n",
       " (NP -> DT NN NN, 313),\n",
       " (NP -> CD, 327),\n",
       " (NP -> DT NNS, 358),\n",
       " (NP -> NP PP-LOC, 363),\n",
       " (NP -> QP -NONE-, 365),\n",
       " (NP -> JJ NN, 390),\n",
       " (NP -> NP SBAR, 409),\n",
       " (NP -> JJ NNS, 653),\n",
       " (NP -> NNP NNP, 734),\n",
       " (NP -> DT JJ NN, 740),\n",
       " (NP -> NNP, 837),\n",
       " (NP -> NNS, 996),\n",
       " (NP -> NN, 1110),\n",
       " (NP -> -NONE-, 1225),\n",
       " (NP -> DT NN, 2020),\n",
       " (NP -> NP PP, 2188)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constructions = find_relevant_constructions('NP')\n",
    "constructions[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5175491986204098, 0.4824508013795902)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_np_pp_frq = 2188 + 363\n",
    "np_n_without_frq = 2020 + 358\n",
    "\n",
    "np_with_pp = np_np_pp_frq / (np_np_pp_frq + np_n_without_frq)\n",
    "np_without = np_n_without_frq / (np_np_pp_frq + np_n_without_frq)\n",
    "\n",
    "(np_with_pp, np_without)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2.3: Regelwahrscheinlichkeiten für DET-Regeln abschätzen\n",
    "\n",
    "\n",
    "#### Zählen Sie auch für die `DET`-Erweiterungen nach *a* bzw. *the*, wie oft sie in der Penn Treebank (`DT`) vorkommen und berechnen Sie die relativen Häufigkeiten als Approximation der Regelwahrscheinlichkeiten:\n",
    "\n",
    "$$P(the \\mid DET) = \\dfrac{count(DET \\rightarrow the)}{count(V\\!P \\rightarrow \\setminus*)}$$\n",
    "\n",
    "**hier:**\n",
    "\n",
    "$$= \\dfrac{count(DET \\rightarrow the)}{count(DET \\rightarrow the) + count(DET \\rightarrow a/an)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(DT -> 'Those', 6),\n",
       " (DT -> 'Another', 6),\n",
       " (DT -> 'neither', 7),\n",
       " (DT -> 'Both', 9),\n",
       " (DT -> 'Each', 9),\n",
       " (DT -> 'No', 10),\n",
       " (DT -> 'half', 10),\n",
       " (DT -> 'All', 12),\n",
       " (DT -> 'An', 18),\n",
       " (DT -> 'every', 19),\n",
       " (DT -> 'These', 22),\n",
       " (DT -> 'Some', 22),\n",
       " (DT -> 'both', 34),\n",
       " (DT -> 'That', 37),\n",
       " (DT -> 'each', 37),\n",
       " (DT -> 'This', 40),\n",
       " (DT -> 'another', 42),\n",
       " (DT -> 'those', 55),\n",
       " (DT -> 'these', 55),\n",
       " (DT -> 'no', 76),\n",
       " (DT -> 'that', 77),\n",
       " (DT -> 'all', 86),\n",
       " (DT -> 'any', 103),\n",
       " (DT -> 'A', 105),\n",
       " (DT -> 'some', 122),\n",
       " (DT -> 'this', 184),\n",
       " (DT -> 'an', 316),\n",
       " (DT -> 'The', 713),\n",
       " (DT -> 'a', 1874),\n",
       " (DT -> 'the', 4038)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constructions = find_relevant_constructions('DT')\n",
    "constructions[-30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6725651189127972, 0.3274348810872027)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "det_the_frq = 4038 + 713\n",
    "det_a_frq = 1874 + 316 + 105 + 18\n",
    "\n",
    "det_the = det_the_frq / (det_the_frq + det_a_frq)\n",
    "det_a = det_a_frq / (det_the_frq + det_a_frq)\n",
    "\n",
    "(det_the, det_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2.4: Erstellen einer PCFG\n",
    "\n",
    "#### Die aus den Daten extrahierten relativen Häufigkeiten sollen nun zur Erstellung einer probabilistischen kontextfreien Grammatik (PCFG)  genutzt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.12585895117540688,\n",
       " 0.8741410488245931,\n",
       " 0.5175491986204098,\n",
       " 0.4824508013795902,\n",
       " 0.6725651189127972,\n",
       " 0.3274348810872027)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(vp_with_pp, vp_without, np_with_pp, np_without, det_the, det_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grammar with 13 productions (start state = S)\n",
      "    S -> NP VP [1.0]\n",
      "    VP -> V NP PP [0.125859]\n",
      "    VP -> V NP [0.874141]\n",
      "    NP -> DET N [0.482451]\n",
      "    NP -> NP PP [0.517549]\n",
      "    PP -> P NP [1.0]\n",
      "    DET -> 'the' [0.672565]\n",
      "    DET -> 'a' [0.327435]\n",
      "    N -> 'boy' [0.4]\n",
      "    N -> 'woman' [0.4]\n",
      "    N -> 'telescope' [0.2]\n",
      "    V -> 'saw' [1.0]\n",
      "    P -> 'with' [1.0]\n"
     ]
    }
   ],
   "source": [
    "pcfg = \"\"\"\n",
    "S -> NP VP     [1.0]\n",
    "VP -> V NP PP  [{}]\n",
    "VP -> V NP     [{}]\n",
    "NP -> DET N    [{}]\n",
    "NP -> NP PP    [{}]\n",
    "PP -> P NP     [1.0]\n",
    "\n",
    "DET -> \"the\"     [{}]\n",
    "DET -> \"a\"       [{}]\n",
    "N -> \"boy\"       [0.4]\n",
    "N -> \"woman\"     [0.4]\n",
    "N -> \"telescope\" [0.2]\n",
    "V -> \"saw\"       [1.0]\n",
    "P -> \"with\"      [1.0]\n",
    "\"\"\".format(\n",
    "    vp_with_pp, vp_without, np_without,\n",
    "    np_with_pp, det_the, det_a\n",
    ")\n",
    "grammar = nltk.PCFG.fromstring(pcfg)\n",
    "print(grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2.5: Verwendung zur Disambiguierung\n",
    "\n",
    "#### Testen Sie Ihre so erstellte Grammatik nun, indem Sie folgenden Satz parsen:\n",
    "\n",
    "- *the boy saw a woman with a telescope*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP (DET the) (N boy))\n",
      "  (VP\n",
      "    (V saw)\n",
      "    (NP\n",
      "      (NP (DET a) (N woman))\n",
      "      (PP (P with) (NP (DET a) (N telescope)))))) (p=0.000117227)\n",
      "                 S                                  \n",
      "     ┌───────────┴────────┐                          \n",
      "     │                    VP                        \n",
      "     │       ┌────────────┴────┐                     \n",
      "     │       │                 NP                   \n",
      "     │       │       ┌─────────┴────┐                \n",
      "     │       │       │              PP              \n",
      "     │       │       │         ┌────┴───┐            \n",
      "     NP      │       NP        │        NP          \n",
      " ┌───┴───┐   │   ┌───┴────┐    │    ┌───┴──────┐     \n",
      "DET      N   V  DET       N    P   DET         N    \n",
      " │       │   │   │        │    │    │          │     \n",
      "the     boy saw  a      woman with  a      telescope\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parser = nltk.ViterbiParser(grammar)\n",
    "for tree in parser.parse(\"the boy saw a woman with a telescope\".split()):\n",
    "    print(tree)\n",
    "    tree.pretty_print(unicodelines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "###  2.6 Wenn Sie sich die extrahierten Wahrscheinlichkeiten und das disambiguierte Ergebnis ansehen, überrascht Sie dann das Ergebnis der Syntaxanalyse?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.060720751855369764"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# relevante Teilwahrscheinlichkeit VP-Attachment:\n",
    "vp_with_pp * np_without\n",
    "#P(VP->VP+NP+PP) * P(NP->DET+N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.218266049165406"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# relevante Teilwahrscheinlichkeit NP-Attachment (s.u.):\n",
    "vp_without * np_with_pp * np_without\n",
    "#P(VP->VP+NP) * P(NP->NP+PP) * P(NP->DET+N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2.7 Vergleichen Sie dieses Ergebnis mit der PCFG-Analyse mit folgenden abweichenden Regelwahrscheinlichkeiten. \n",
    "\n",
    "### Warum wird hier trotz `vp_with_pp < np_with_pp` der VP-Attachment-Baum als der wahrscheinlichere ausgewählt? \n",
    "\n",
    "##### (Beachten Sie die Anzahl an Regelanwendungen in den beiden Syntaxbäumen!)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp_with_pp = 0.2\n",
    "vp_without = 0.8\n",
    "np_with_pp = 0.22\n",
    "np_without = 0.78"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grammar with 13 productions (start state = S)\n",
      "    S -> NP VP [1.0]\n",
      "    VP -> V NP PP [0.2]\n",
      "    VP -> V NP [0.8]\n",
      "    NP -> DET N [0.78]\n",
      "    NP -> NP PP [0.22]\n",
      "    PP -> P NP [1.0]\n",
      "    DET -> 'the' [0.672565]\n",
      "    DET -> 'a' [0.327435]\n",
      "    N -> 'boy' [0.4]\n",
      "    N -> 'woman' [0.4]\n",
      "    N -> 'telescope' [0.2]\n",
      "    V -> 'saw' [1.0]\n",
      "    P -> 'with' [1.0]\n"
     ]
    }
   ],
   "source": [
    "pcfg = \"\"\"\n",
    "S -> NP VP     [1.0]\n",
    "VP -> V NP PP  [{}]\n",
    "VP -> V NP     [{}]\n",
    "NP -> DET N    [{}]\n",
    "NP -> NP PP    [{}]\n",
    "PP -> P NP     [1.0]\n",
    "\n",
    "DET -> \"the\"     [{}]\n",
    "DET -> \"a\"       [{}]\n",
    "N -> \"boy\"       [0.4]\n",
    "N -> \"woman\"     [0.4]\n",
    "N -> \"telescope\" [0.2]\n",
    "V -> \"saw\"       [1.0]\n",
    "P -> \"with\"      [1.0]\n",
    "\"\"\".format(\n",
    "    vp_with_pp, vp_without, np_without,\n",
    "    np_with_pp, det_the, det_a\n",
    ")\n",
    "\n",
    "grammar = nltk.PCFG.fromstring(pcfg)\n",
    "print(grammar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP (DET the) (N boy))\n",
      "  (VP\n",
      "    (V saw)\n",
      "    (NP (DET a) (N woman))\n",
      "    (PP (P with) (NP (DET a) (N telescope))))) (p=0.000219002)\n",
      "                 S                                  \n",
      "     ┌───────────┴────────┐                          \n",
      "     │                    VP                        \n",
      "     │       ┌───────┬────┴─────────┐                \n",
      "     │       │       │              PP              \n",
      "     │       │       │         ┌────┴───┐            \n",
      "     NP      │       NP        │        NP          \n",
      " ┌───┴───┐   │   ┌───┴────┐    │    ┌───┴──────┐     \n",
      "DET      N   V  DET       N    P   DET         N    \n",
      " │       │   │   │        │    │    │          │     \n",
      "the     boy saw  a      woman with  a      telescope\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parser = nltk.ViterbiParser(grammar)\n",
    "for tree in parser.parse(\"the boy saw a woman with a telescope\".split()):\n",
    "    print(tree)\n",
    "    tree.pretty_print(unicodelines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15600000000000003"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# relevante Teilwahrscheinlichkeit VP-Attachment:\n",
    "vp_with_pp * np_without\n",
    "#P(VP->VP+NP+PP) * P(NP->DET+N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13728"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# relevante Teilwahrscheinlichkeit NP-Attachment (1 Regel mehr im Baum, wegen rekursiver Regel NP->NP+PP):\n",
    "vp_without * np_with_pp * np_without\n",
    "#P(VP->VP+NP) * P(NP->NP+PP) * P(NP->DET+N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### vgl. die Anzahl der Regeln in den beiden Bäumen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 S                                  \n",
      "     ┌───────────┴────────┐                          \n",
      "     │                    VP                        \n",
      "     │       ┌───────┬────┴─────────┐                \n",
      "     │       │       │              PP              \n",
      "     │       │       │         ┌────┴───┐            \n",
      "     NP      │       NP        │        NP          \n",
      " ┌───┴───┐   │   ┌───┴────┐    │    ┌───┴──────┐     \n",
      "DET      N   V  DET       N    P   DET         N    \n",
      " │       │   │   │        │    │    │          │     \n",
      "the     boy saw  a      woman with  a      telescope\n",
      "\n",
      "0 S -> NP VP\n",
      "1 NP -> DET N\n",
      "2 DET -> 'the'\n",
      "3 N -> 'boy'\n",
      "4 VP -> V NP PP\n",
      "5 V -> 'saw'\n",
      "6 NP -> DET N\n",
      "7 DET -> 'a'\n",
      "8 N -> 'woman'\n",
      "9 PP -> P NP\n",
      "10 P -> 'with'\n",
      "11 NP -> DET N\n",
      "12 DET -> 'a'\n",
      "13 N -> 'telescope'\n",
      "                 S                                  \n",
      "     ┌───────────┴────────┐                          \n",
      "     │                    VP                        \n",
      "     │       ┌────────────┴────┐                     \n",
      "     │       │                 NP                   \n",
      "     │       │       ┌─────────┴────┐                \n",
      "     │       │       │              PP              \n",
      "     │       │       │         ┌────┴───┐            \n",
      "     NP      │       NP        │        NP          \n",
      " ┌───┴───┐   │   ┌───┴────┐    │    ┌───┴──────┐     \n",
      "DET      N   V  DET       N    P   DET         N    \n",
      " │       │   │   │        │    │    │          │     \n",
      "the     boy saw  a      woman with  a      telescope\n",
      "\n",
      "0 S -> NP VP\n",
      "1 NP -> DET N\n",
      "2 DET -> 'the'\n",
      "3 N -> 'boy'\n",
      "4 VP -> V NP\n",
      "5 V -> 'saw'\n",
      "6 NP -> NP PP\n",
      "7 NP -> DET N\n",
      "8 DET -> 'a'\n",
      "9 N -> 'woman'\n",
      "10 PP -> P NP\n",
      "11 P -> 'with'\n",
      "12 NP -> DET N\n",
      "13 DET -> 'a'\n",
      "14 N -> 'telescope'\n"
     ]
    }
   ],
   "source": [
    "sentence = \"the boy saw a woman with a telescope\"\n",
    "parser = nltk.ChartParser(grammar,trace=0)\n",
    "\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree.pretty_print(unicodelines=True)\n",
    "    for i, prod in enumerate(tree.productions()):\n",
    "        print(i, prod)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
