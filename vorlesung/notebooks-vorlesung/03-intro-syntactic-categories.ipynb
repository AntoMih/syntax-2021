{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Vorlesung 'Syntax natürlicher Sprachen'***\n",
    "\n",
    "--- \n",
    "# Intro Vorlesung 3: Syntaktische Kategorien\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## POS-Tagsets\n",
    "- http://www.nltk.org/book/ch05.html#tab-universal-tagset\n",
    "- https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
    "- https://www.linguistik.hu-berlin.de/de/institut/professuren/korpuslinguistik/mitarbeiter-innen/hagen/STTS_Tagset_Tiger\n",
    "- https://universaldependencies.org/u/pos/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VBG: verb, present participle or gerund\n",
      "    telegraphing stirring focusing angering judging stalling lactating\n",
      "    hankerin' alleging veering capping approaching traveling besieging\n",
      "    encrypting interrupting erasing wincing ...\n"
     ]
    }
   ],
   "source": [
    "#nltk: Penn Treebank POS Tagset:\n",
    "nltk.help.upenn_tagset('VBG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syntaktische Tagsets\n",
    "\n",
    "### Phrasenstruktur\n",
    "- http://www.surdeanu.info/mihai/teaching/ista555-fall13/readings/PennTreebankConstituents.html\n",
    "- https://www.linguistik.hu-berlin.de/de/institut/professuren/korpuslinguistik/mitarbeiter-innen/hagen/Tiger_Knotenlabels\n",
    "\n",
    "### Dependenzrelationen\n",
    "- https://universaldependencies.org/u/dep/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Wortarten (Präterminale)\n",
    "\n",
    "### Generierung von POS-Mustern mit rekursiven Phrasenstrukturregeln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl an POS-Mustern:  \n",
      "\tbei 6 Regelanwendungen: 24 \n",
      "\tbei 7 Regelanwendungen: 64 \n",
      "\tbei 8 Regelanwendungen: 408\n"
     ]
    }
   ],
   "source": [
    "# http://www.nltk.org/howto/generate.html\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S -> NP VP\n",
    "    PP -> P NP\n",
    "    NP -> Det N | Det N PP | N\n",
    "    VP -> V NP | VP PP\n",
    "    Det -> 'Det'\n",
    "    N -> 'N'\n",
    "    V -> 'V'\n",
    "    P -> 'P'\n",
    "\"\"\")\n",
    "\n",
    "#Generierung:\n",
    "from nltk.parse.generate import generate\n",
    "print('Anzahl an POS-Mustern: ', \n",
    "    '\\n\\tbei 6 Regelanwendungen:', len(list(generate(grammar, depth=6))), \n",
    "    '\\n\\tbei 7 Regelanwendungen:', len(list(generate(grammar, depth=7))),\n",
    "    '\\n\\tbei 8 Regelanwendungen:', len(list(generate(grammar, depth=8))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Det N V Det N\n",
      "Det N V Det N P Det N\n",
      "Det N V Det N P N\n",
      "Det N V N\n",
      "Det N V Det N P Det N\n",
      "Det N V Det N P N\n",
      "Det N V N P Det N\n",
      "Det N V N P N\n",
      "Det N V Det N P Det N P Det N\n",
      "Det N V Det N P Det N P N\n",
      "Det N V Det N P N P Det N\n",
      "Det N V Det N P N P N\n",
      "Det N V N P Det N P Det N\n",
      "Det N V N P Det N P N\n",
      "Det N V N P N P Det N\n",
      "Det N V N P N P N\n",
      "Det N P Det N V Det N\n",
      "Det N P Det N V Det N P Det N\n",
      "Det N P Det N V Det N P N\n",
      "Det N P Det N V N\n",
      "Det N P Det N V Det N P Det N\n",
      "Det N P Det N V Det N P N\n",
      "Det N P Det N V N P Det N\n",
      "Det N P Det N V N P N\n",
      "Det N P Det N V Det N P Det N P Det N\n",
      "Det N P Det N V Det N P Det N P N\n",
      "Det N P Det N V Det N P N P Det N\n",
      "Det N P Det N V Det N P N P N\n",
      "Det N P Det N V N P Det N P Det N\n",
      "Det N P Det N V N P Det N P N\n",
      "Det N P Det N V N P N P Det N\n",
      "Det N P Det N V N P N P N\n",
      "Det N P N V Det N\n",
      "Det N P N V Det N P Det N\n",
      "Det N P N V Det N P N\n",
      "Det N P N V N\n",
      "Det N P N V Det N P Det N\n",
      "Det N P N V Det N P N\n",
      "Det N P N V N P Det N\n",
      "Det N P N V N P N\n",
      "Det N P N V Det N P Det N P Det N\n",
      "Det N P N V Det N P Det N P N\n",
      "Det N P N V Det N P N P Det N\n",
      "Det N P N V Det N P N P N\n",
      "Det N P N V N P Det N P Det N\n",
      "Det N P N V N P Det N P N\n",
      "Det N P N V N P N P Det N\n",
      "Det N P N V N P N P N\n",
      "N V Det N\n",
      "N V Det N P Det N\n",
      "N V Det N P N\n",
      "N V N\n",
      "N V Det N P Det N\n",
      "N V Det N P N\n",
      "N V N P Det N\n",
      "N V N P N\n",
      "N V Det N P Det N P Det N\n",
      "N V Det N P Det N P N\n",
      "N V Det N P N P Det N\n",
      "N V Det N P N P N\n",
      "N V N P Det N P Det N\n",
      "N V N P Det N P N\n",
      "N V N P N P Det N\n",
      "N V N P N P N\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate\n",
    "for sentence in generate(grammar, depth=7):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suche kontextäquivalenter Wörter im Korpus mit NLTK (paradigmatische Dimension)\n",
    "\n",
    "http://www.nltk.org/book/ch05.html#using-a-tagger:\n",
    "\n",
    "> Lexical categories like \"noun\" and part-of-speech tags like NN seem to have their uses, but the details will be obscure to many readers. You might wonder what justification there is for introducing this extra level of information. Many of these categories arise from superficial analysis the distribution of words in text. Consider the following analysis involving *woman* (a noun), *bought* (a verb), *over* (a preposition), and *the* (a determiner). The `text.similar()` method takes a word *w*, finds all contexts *w1 w w2*, then finds all words *w'* that appear in the same context, i.e. *w1 w' w2*.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://www.nltk.org/book/ch05.html#using-a-tagger\n",
    "\n",
    "from nltk.corpus import brown\n",
    "text = nltk.Text(word.lower() for word in nltk.corpus.brown.words())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Observe that searching for *woman* finds nouns; searching for *bought* mostly finds verbs; searching for *over* generally finds prepositions; searching for *the* finds several determiners. A tagger can correctly identify the tags on these words in the context of a sentence, e.g. *The woman bought over $150,000 worth of clothes.* (http://www.nltk.org/book/ch05.html#using-a-tagger)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man time day year car moment world house family child country boy\n",
      "state job place way war girl work word\n"
     ]
    }
   ],
   "source": [
    "text.similar('woman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "made said done put had seen found given left heard was been brought\n",
      "set got that took in told felt\n"
     ]
    }
   ],
   "source": [
    "text.similar('bought')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in on to of and for with from at by that into as up out down through\n",
      "is all about\n"
     ]
    }
   ],
   "source": [
    "text.similar('over')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a his this their its her an that our any all one these my in your no\n",
      "some other and\n"
     ]
    }
   ],
   "source": [
    "text.similar('the')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "### Suche nach nominalen Mustern im Korpus  (syntagmatische Dimension)\n",
    "\n",
    "http://www.nltk.org/book/ch05.html#nouns:\n",
    "\n",
    "> Let's inspect some tagged text to see what parts of speech occur before a noun, with the most frequent ones first. To begin with, we construct a list of bigrams whose members are themselves word-tag pairs such as `(('The', 'DET'), ('Fulton', 'NP'))` and `(('Fulton', 'NP'), ('County', 'N'))`. Then we construct a `FreqDist` from the tag parts of the bigrams.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NOUN', 7959),\n",
       " ('DET', 7373),\n",
       " ('ADJ', 4761),\n",
       " ('ADP', 3781),\n",
       " ('.', 2796),\n",
       " ('VERB', 1842),\n",
       " ('CONJ', 938),\n",
       " ('NUM', 894),\n",
       " ('ADV', 186),\n",
       " ('PRT', 94),\n",
       " ('PRON', 19),\n",
       " ('X', 11)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "brown_news_tagged = brown.tagged_words(categories='news', tagset='universal')\n",
    "word_tag_pairs = nltk.bigrams(brown_news_tagged)\n",
    "noun_preceders = [a[1] for (a, b) in word_tag_pairs if b[1] == 'NOUN']\n",
    "fdist = nltk.FreqDist(noun_preceders)\n",
    "[(tag, fq) for (tag, fq) in fdist.most_common()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This confirms our assertion that nouns occur after determiners and adjectives, including numeral adjectives (tagged as `NUM``). (http://www.nltk.org/book/ch05.html#nouns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "### Adjektive als Klasse distributionsäquivalenter Wörter:\n",
    "\n",
    "#### Suche nach distributionsäquivalenten Wörtern (Auftreten in gleichen Kontexten):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "little new first good small large great the old other strong young\n",
      "major white second short beautiful a best long\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "text = nltk.Text(word.lower() for word in nltk.corpus.brown.words())\n",
    "text.similar('big')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wortarten-Kontexte von distributionsäquivalenter Wörtern (als Vertreter einer Distributionsklasse):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('DET', 'NOUN'), 193),\n",
       " (('ADP', 'NOUN'), 42),\n",
       " (('VERB', 'NOUN'), 36),\n",
       " (('DET', 'ADJ'), 30),\n",
       " (('DET', 'NUM'), 22),\n",
       " (('NOUN', 'NOUN'), 13),\n",
       " (('DET', 'ADP'), 13),\n",
       " (('ADJ', 'NOUN'), 12),\n",
       " (('CONJ', 'NOUN'), 10),\n",
       " (('NUM', 'NOUN'), 10),\n",
       " (('NOUN', 'ADJ'), 8),\n",
       " (('ADV', 'NOUN'), 8),\n",
       " (('VERB', '.'), 7),\n",
       " (('.', 'NOUN'), 6),\n",
       " (('DET', '.'), 5),\n",
       " (('ADV', 'ADP'), 5),\n",
       " (('ADV', '.'), 5),\n",
       " (('NOUN', '.'), 4),\n",
       " (('VERB', 'VERB'), 4),\n",
       " (('DET', 'VERB'), 4),\n",
       " (('NOUN', 'VERB'), 4),\n",
       " (('ADP', 'ADJ'), 3),\n",
       " (('NUM', 'ADJ'), 3),\n",
       " (('ADP', '.'), 3),\n",
       " (('PRON', 'VERB'), 3),\n",
       " (('PRT', 'NOUN'), 3),\n",
       " (('ADV', 'DET'), 3),\n",
       " (('ADV', 'VERB'), 3),\n",
       " (('ADJ', 'ADJ'), 2),\n",
       " (('VERB', 'ADJ'), 2),\n",
       " (('VERB', 'ADV'), 2),\n",
       " (('DET', 'PRT'), 2),\n",
       " (('ADP', 'VERB'), 2),\n",
       " (('ADP', 'CONJ'), 2),\n",
       " (('DET', 'ADV'), 2),\n",
       " (('PRT', 'VERB'), 1),\n",
       " (('VERB', 'DET'), 1),\n",
       " (('DET', 'X'), 1),\n",
       " (('DET', 'CONJ'), 1),\n",
       " (('NOUN', 'NUM'), 1),\n",
       " (('ADV', 'CONJ'), 1),\n",
       " (('ADP', 'ADP'), 1),\n",
       " (('ADP', 'NUM'), 1),\n",
       " (('VERB', 'CONJ'), 1),\n",
       " (('ADV', 'PRT'), 1),\n",
       " (('ADJ', 'CONJ'), 1),\n",
       " (('NOUN', 'ADP'), 1),\n",
       " (('ADJ', 'NUM'), 1),\n",
       " (('ADV', 'ADV'), 1),\n",
       " (('CONJ', 'ADJ'), 1),\n",
       " (('CONJ', 'ADV'), 1),\n",
       " (('VERB', 'ADP'), 1),\n",
       " (('NOUN', 'ADV'), 1),\n",
       " (('ADP', 'DET'), 1),\n",
       " (('PRON', 'NOUN'), 1)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rechter und linker Kontext für eine Menge distributionsäquivalenter Wörter:\n",
    "from nltk.corpus import brown\n",
    "brown_news_tagged = brown.tagged_words(categories='news', tagset='universal')\n",
    "word_tag_trigrams = nltk.trigrams(brown_news_tagged)\n",
    "adj_contexts = [(a[1], c[1]) for (a, b, c) in word_tag_trigrams if b[0] in ('big', 'little', 'new', 'first', 'good', 'small', 'large', 'great')]\n",
    "\n",
    "fdist = nltk.FreqDist(adj_contexts)\n",
    "[(tag, fq) for (tag, fq) in fdist.most_common()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('DET', 'NOUN'), 2081),\n",
       " (('ADP', 'NOUN'), 745),\n",
       " (('NOUN', 'NOUN'), 368),\n",
       " (('ADJ', 'NOUN'), 363),\n",
       " (('VERB', 'NOUN'), 351),\n",
       " (('.', 'NOUN'), 332),\n",
       " (('DET', 'ADJ'), 218),\n",
       " (('CONJ', 'NOUN'), 214),\n",
       " (('ADV', 'NOUN'), 154),\n",
       " (('VERB', 'ADP'), 145),\n",
       " (('NUM', 'NOUN'), 129),\n",
       " (('DET', '.'), 104),\n",
       " (('ADV', 'ADP'), 100),\n",
       " (('ADV', '.'), 83),\n",
       " (('DET', 'NUM'), 83),\n",
       " (('VERB', '.'), 77),\n",
       " (('VERB', 'PRT'), 61),\n",
       " (('.', 'ADP'), 57),\n",
       " (('DET', 'CONJ'), 56),\n",
       " (('NOUN', 'ADP'), 56),\n",
       " (('ADP', 'ADJ'), 56),\n",
       " (('DET', 'ADP'), 56),\n",
       " (('.', '.'), 53),\n",
       " (('DET', 'VERB'), 44),\n",
       " (('ADP', '.'), 42),\n",
       " (('ADP', 'ADP'), 38),\n",
       " (('NOUN', '.'), 33),\n",
       " (('VERB', 'CONJ'), 32),\n",
       " (('ADP', 'CONJ'), 30),\n",
       " (('.', 'CONJ'), 27),\n",
       " (('.', 'ADJ'), 26),\n",
       " (('CONJ', '.'), 25),\n",
       " (('VERB', 'ADJ'), 25),\n",
       " (('NOUN', 'ADJ'), 24),\n",
       " (('ADJ', 'ADJ'), 21),\n",
       " (('PRT', 'NOUN'), 19),\n",
       " (('CONJ', 'ADP'), 18),\n",
       " (('CONJ', 'ADJ'), 17),\n",
       " (('ADP', 'NUM'), 16),\n",
       " (('ADV', 'PRT'), 13),\n",
       " (('NOUN', 'VERB'), 13),\n",
       " (('VERB', 'ADV'), 13),\n",
       " (('ADV', 'VERB'), 12),\n",
       " (('VERB', 'NUM'), 12),\n",
       " (('ADV', 'ADJ'), 11),\n",
       " (('ADV', 'CONJ'), 10),\n",
       " (('ADP', 'DET'), 10),\n",
       " (('VERB', 'VERB'), 10),\n",
       " (('NUM', 'ADJ'), 9),\n",
       " (('VERB', 'DET'), 9),\n",
       " (('ADJ', 'CONJ'), 9),\n",
       " (('ADP', 'VERB'), 9),\n",
       " (('ADV', 'DET'), 9),\n",
       " (('NOUN', 'PRT'), 8),\n",
       " (('PRT', '.'), 8),\n",
       " (('DET', 'ADV'), 7),\n",
       " (('ADJ', '.'), 7),\n",
       " (('PRON', 'ADP'), 7),\n",
       " (('.', 'VERB'), 6),\n",
       " (('ADV', 'ADV'), 6),\n",
       " (('CONJ', 'VERB'), 6),\n",
       " (('DET', 'PRT'), 6),\n",
       " (('NUM', 'ADP'), 6),\n",
       " (('PRT', 'ADP'), 6),\n",
       " (('PRT', 'PRT'), 5),\n",
       " (('PRON', 'NOUN'), 5),\n",
       " (('NOUN', 'DET'), 5),\n",
       " (('NOUN', 'NUM'), 5),\n",
       " (('NUM', '.'), 5),\n",
       " (('CONJ', 'CONJ'), 4),\n",
       " (('ADJ', 'VERB'), 4),\n",
       " (('.', 'PRT'), 4),\n",
       " (('ADP', 'PRT'), 4),\n",
       " (('PRON', 'PRT'), 4),\n",
       " (('NOUN', 'CONJ'), 4),\n",
       " (('.', 'NUM'), 4),\n",
       " (('DET', 'PRON'), 4),\n",
       " (('CONJ', 'ADV'), 4),\n",
       " (('CONJ', 'PRT'), 3),\n",
       " (('VERB', 'PRON'), 3),\n",
       " (('NOUN', 'ADV'), 3),\n",
       " (('ADJ', 'NUM'), 3),\n",
       " (('.', 'DET'), 3),\n",
       " (('ADV', 'PRON'), 3),\n",
       " (('NOUN', 'PRON'), 2),\n",
       " (('ADP', 'ADV'), 2),\n",
       " (('PRON', 'VERB'), 2),\n",
       " (('CONJ', 'NUM'), 2),\n",
       " (('ADJ', 'PRON'), 2),\n",
       " (('PRON', 'ADJ'), 2),\n",
       " (('PRON', '.'), 2),\n",
       " (('ADV', 'NUM'), 2),\n",
       " (('NUM', 'CONJ'), 1),\n",
       " (('DET', 'X'), 1),\n",
       " (('PRT', 'PRON'), 1),\n",
       " (('NUM', 'VERB'), 1),\n",
       " (('.', 'ADV'), 1),\n",
       " (('.', 'PRON'), 1),\n",
       " (('PRON', 'ADV'), 1),\n",
       " (('ADP', 'PRON'), 1),\n",
       " (('PRT', 'CONJ'), 1),\n",
       " (('NOUN', 'X'), 1)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Linker und rechter Kontext für ADJ:\n",
    "from nltk.corpus import brown\n",
    "brown_news_tagged = brown.tagged_words(categories='news', tagset='universal')\n",
    "word_tag_trigrams = nltk.trigrams(brown_news_tagged)\n",
    "adj_contexts = [(a[1], c[1]) for (a, b, c) in word_tag_trigrams if b[1] == 'ADJ']\n",
    "\n",
    "fdist = nltk.FreqDist(adj_contexts)\n",
    "[(tag, fq) for (tag, fq) in fdist.most_common()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('is', 77),\n",
       " ('be', 67),\n",
       " ('was', 44),\n",
       " ('are', 37),\n",
       " ('were', 26),\n",
       " ('been', 13),\n",
       " ('had', 11),\n",
       " ('made', 10),\n",
       " ('get', 9),\n",
       " ('become', 8),\n",
       " ('provide', 7),\n",
       " ('make', 7),\n",
       " ('has', 7),\n",
       " ('have', 6),\n",
       " ('getting', 4),\n",
       " ('give', 4),\n",
       " ('said', 4),\n",
       " (\"isn't\", 4),\n",
       " ('brought', 3),\n",
       " ('left', 3)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Beispiele aus Korpus für prädikative ('is good') bzw. adverbiale Verwendung ('left fast')\n",
    "from nltk.corpus import brown\n",
    "brown_news_tagged = brown.tagged_words(categories='news', tagset='universal')\n",
    "word_tag_pairs = nltk.bigrams(brown_news_tagged)\n",
    "noun_preceders = [a[0] for (a, b) in word_tag_pairs if b[1] == 'ADJ' and a[1] == 'VERB']\n",
    "fdist = nltk.FreqDist(noun_preceders)\n",
    "[(tag, fq) for (tag, fq) in fdist.most_common(20)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "098dd75f65594c0f992ddeffeb8523e3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.2.0",
      "model_name": "SliderStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "0ccfa5129ab64950adda077f6ac8f44a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.2.0",
      "model_name": "IntSliderModel",
      "state": {
       "layout": "IPY_MODEL_641f3cf31a334ee6810a9a92f93e89a7",
       "style": "IPY_MODEL_63aadafcc3504a3b8b15fdea9d4ec244",
       "value": 50
      }
     },
     "1b37a149a74c40c68d34c61b481048f8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "367694b2ecc94715a20952236f9ced88": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3d6ebd239fc84a8e95b3007988e38134": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.2.0",
      "model_name": "SliderStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "63aadafcc3504a3b8b15fdea9d4ec244": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.2.0",
      "model_name": "SliderStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "641f3cf31a334ee6810a9a92f93e89a7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "993ec756027845c19085347ca5f9f6ce": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.2.0",
      "model_name": "SliderStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "bb743dc2dd2d4bb08dd2c5255e1d87c6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.2.0",
      "model_name": "SliderStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "cb4a4abdac584f78ac3b37579ac33b10": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.2.0",
      "model_name": "IntSliderModel",
      "state": {
       "layout": "IPY_MODEL_f25c2eb22704411b9981f8047a2c0182",
       "style": "IPY_MODEL_993ec756027845c19085347ca5f9f6ce",
       "value": 50
      }
     },
     "cfbb8ba5969a49e18a1733c50e6b73e4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.2.0",
      "model_name": "IntSliderModel",
      "state": {
       "layout": "IPY_MODEL_1b37a149a74c40c68d34c61b481048f8",
       "style": "IPY_MODEL_3d6ebd239fc84a8e95b3007988e38134",
       "value": 50
      }
     },
     "da2e37629b7141b8a194c275f89ccef5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "eafa48b852af4f40b414b8d4f0b90c7a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.2.0",
      "model_name": "IntSliderModel",
      "state": {
       "layout": "IPY_MODEL_da2e37629b7141b8a194c275f89ccef5",
       "style": "IPY_MODEL_bb743dc2dd2d4bb08dd2c5255e1d87c6"
      }
     },
     "f196171317cf493fabedf854f59c1d44": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.2.0",
      "model_name": "IntSliderModel",
      "state": {
       "layout": "IPY_MODEL_367694b2ecc94715a20952236f9ced88",
       "style": "IPY_MODEL_098dd75f65594c0f992ddeffeb8523e3"
      }
     },
     "f25c2eb22704411b9981f8047a2c0182": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
